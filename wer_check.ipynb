{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WER / CER 계산 코드 (구현)\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "# locale.getpreferredencoding()\n",
    "# !pip install Levenshtein\n",
    "import Levenshtein as Lev\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_wer(ref, hyp ,debug=False):\n",
    "        # Handle NaN values by converting them to empty strings\n",
    "    if pd.isna(ref):\n",
    "        ref = \"\"\n",
    "    if pd.isna(hyp):\n",
    "        hyp = \"\"\n",
    "    r = ref.split()\n",
    "    h = hyp.split()\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    # backtrace will hold the operations we've done.\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "\n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "\n",
    "    DEL_PENALTY=1 # Tact\n",
    "    INS_PENALTY=1 # Tact\n",
    "    SUB_PENALTY=1 # Tact\n",
    "    # First column represents the case where we achieve zero\n",
    "    # hypothesis words by deleting all reference words.\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "\n",
    "    # First row represents the case where we achieve the hypothesis\n",
    "    # by inserting all hypothesis words into a zero-length reference.\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "\n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "\n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        print(\"OP\\tREF\\tHYP\")\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    if debug:\n",
    "        lines = reversed(lines)\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "        print(\"Ncor \" + str(numCor))\n",
    "        print(\"Nsub \" + str(numSub))\n",
    "        print(\"Ndel \" + str(numDel))\n",
    "        print(\"Nins \" + str(numIns))\n",
    "    return numCor, numSub, numDel, numIns, (numSub + numDel + numIns) / (float) (len(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위스퍼\n",
    "def get_mean_wer_whisper(df):\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_text'], row['whisper_text'])[4], axis=1)\n",
    "    return df['wer'].mean()\n",
    "\n",
    "# 위스퍼+라마기본\n",
    "def get_mean_wer_llama(df):\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_text'], row['llm_text'])[4], axis=1)\n",
    "    return df['wer'].mean()\n",
    "\n",
    "# 위스퍼+라마파인튜닝\n",
    "def get_mean_wer_llama_ft(df):\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_text'], row['llm_output_text'])[4], axis=1)\n",
    "    return df['wer'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0405270031874403"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('atco2_test_dictation_by_whisper_small.csv', encoding='UTF-8')\n",
    "mean_wer_1 = get_mean_wer_whisper(df)\n",
    "mean_wer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0495432499523087"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_finetuned.csv', encoding='UTF-8')\n",
    "mean_wer_2 = get_mean_wer_whisper(df)\n",
    "mean_wer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.068548207134803"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_small_and_llama2_original.csv', encoding='UTF-8')\n",
    "mean_wer_3 = get_mean_wer_llama(df)\n",
    "mean_wer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9536716822147444"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_finetuned_and_llama2_original.csv', encoding='UTF-8')\n",
    "mean_wer_4 = get_mean_wer_llama(df)\n",
    "mean_wer_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8557662425136696"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Whisper에 llama2 finetuned 붙여서 ATCO2 WER 뽑기_결과.csv', encoding='UTF-8')\n",
    "mean_wer_5 = get_mean_wer_llama_ft(df)\n",
    "mean_wer_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7405766128636935"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Whisper 파인튜닝한 모델에 llama2 finetuned 붙여서 ATCO2 WER 뽑기_결과.csv', encoding='UTF-8')\n",
    "mean_wer_6 = get_mean_wer_llama_ft(df)\n",
    "mean_wer_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "위스퍼 기본모델              :  1.0405270031874403\n",
      "위스퍼 파인튜닝              :  1.0495432499523087\n",
      "위스퍼 기본모델 + 라마 기본모델 :  1.068548207134803\n",
      "위스퍼 파인튜닝 + 라마 기본모델 :  0.9536716822147444\n",
      "위스퍼 기본모델 + 라마 파인튜닝 :  0.8557662425136696\n",
      "위스퍼 기본모델 + 라마 파인튜닝 :  0.7405766128636935\n"
     ]
    }
   ],
   "source": [
    "print(\"위스퍼 기본모델              : \", mean_wer_1)\n",
    "print(\"위스퍼 파인튜닝              : \", mean_wer_2)\n",
    "print(\"위스퍼 기본모델 + 라마 기본모델 : \", mean_wer_3)\n",
    "print(\"위스퍼 파인튜닝 + 라마 기본모델 : \", mean_wer_4)\n",
    "print(\"위스퍼 기본모델 + 라마 파인튜닝 : \", mean_wer_5)\n",
    "print(\"위스퍼 기본모델 + 라마 파인튜닝 : \", mean_wer_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알파벳 -> 숫자\n",
    "import re\n",
    "\n",
    "# 숫자 단어와 실제 숫자의 매핑\n",
    "number_map = {\n",
    "    'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',\n",
    "    'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',\n",
    "    'ten': '10', 'eleven': '11', 'twelve': '12', 'thirteen': '13', 'fourteen': '14',\n",
    "    'fifteen': '15', 'sixteen': '16', 'seventeen': '17', 'eighteen': '18', 'nineteen': '19',\n",
    "    'twenty': '20', 'thirty': '30','forty': '40', 'fifty': '50', 'sixty': '60', \n",
    "    'seventy': '70', 'eighty': '80', 'ninety': '90',\n",
    "    \n",
    "}\n",
    "\n",
    "# 숫자 단어를 숫자로 변환하는 함수\n",
    "def convert_word_to_number(word):\n",
    "    return int(number_map[word])\n",
    "\n",
    "\n",
    "# thousand, hundred 가 모두 있는 경우만 처리\n",
    "def replace_thousands_and_hundreds(text):\n",
    "    # 정규식 패턴 정의\n",
    "    pattern = re.compile(r'(\\b(?:zero|one|two|three|four|five|six|seven|eight|nine)\\sthousand\\s(?:zero|one|two|three|four|five|six|seven|eight|nine)\\shundred\\b)')\n",
    "\n",
    "    # 숫자 단어를 숫자로 변환하는 함수\n",
    "    def convert_match(match):\n",
    "        words = match.group(0).split()\n",
    "        thousands = convert_word_to_number(words[0])\n",
    "        hundreds = convert_word_to_number(words[2])\n",
    "        return str(thousands * 1000 + hundreds * 100)\n",
    "\n",
    "    return pattern.sub(convert_match, text)\n",
    "\n",
    "\n",
    "# thousand 만 있는 경우 처리\n",
    "def replace_thousands(text):\n",
    "    # 정규식 패턴 정의\n",
    "    pattern = re.compile(r'(\\b(?:zero|one|two|three|four|five|six|seven|eight|nine)\\sthousand\\b)')\n",
    "\n",
    "    # 숫자 단어를 숫자로 변환하는 함수\n",
    "    def convert_match(match):\n",
    "        words = match.group(0).split()\n",
    "        thousands = convert_word_to_number(words[0])\n",
    "        \n",
    "        return str(thousands * 1000)\n",
    "\n",
    "    return pattern.sub(convert_match, text)\n",
    "\n",
    "\n",
    "# hundred 만 있는 경우 처리\n",
    "def replace_hundreds(text):\n",
    "    # 정규식 패턴 정의\n",
    "    pattern = re.compile(r'(\\b(?:zero|one|two|three|four|five|six|seven|eight|nine)\\shundred\\b)')\n",
    "\n",
    "    # 숫자 단어를 숫자로 변환하는 함수\n",
    "    def convert_match(match):\n",
    "        words = match.group(0).split()\n",
    "        hundreds = convert_word_to_number(words[0])\n",
    "        \n",
    "        return str(hundreds * 100)\n",
    "\n",
    "    return pattern.sub(convert_match, text)\n",
    "\n",
    "\n",
    "reverse_number_map = {\n",
    "    '1': 'one', '2': 'two', '3': 'three', '4': 'four', '5': 'five',\n",
    "    '6': 'six', '7': 'seven', '8': 'eight', '9': 'nine'\n",
    "}\n",
    "# forty five 등의 경우 four five 로 변환\n",
    "def convert_big_numbers(text):\n",
    "    # 숫자 단어들을 찾아 매핑을 통해 변환\n",
    "    def replace_numbers(match):\n",
    "        words = match.group(0).split()\n",
    "        reverse_key = str(int(int(number_map[words[0]]) / 10))\n",
    "        words[0] = reverse_number_map[reverse_key]\n",
    "        return ' '.join(word for word in words)\n",
    "\n",
    "    # 정규식을 사용하여 숫자 단어들의 패턴을 찾음\n",
    "    pattern = re.compile(r'(?:ten|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety)\\s+(?:one|two|three|four|five|six|seven|eight|nine)')\n",
    "    return pattern.sub(replace_numbers, text)\n",
    "\n",
    "\n",
    "# 숫자 단어를 숫자로 변환하는 함수\n",
    "def convert_words_to_numbers(text):\n",
    "    # 숫자 단어들을 찾아 매핑을 통해 변환\n",
    "    def replace_numbers(match):\n",
    "        words = match.group(0).split()\n",
    "        # 'decimal'을 포함한 경우 소수점으로 변환\n",
    "        if 'decimal' in words:\n",
    "            decimal_index = words.index('decimal')\n",
    "            integer_part = ''.join(number_map[word] for word in words[:decimal_index])\n",
    "            decimal_part = ''.join(number_map[word] for word in words[decimal_index+1:])\n",
    "            return f\"{integer_part}.{decimal_part}\"\n",
    "        else:\n",
    "            return ''.join(number_map[word] for word in words)\n",
    "\n",
    "    # 정규식을 사용하여 숫자 단어들의 패턴을 찾음\n",
    "    pattern = re.compile(r'\\b(?:zero|one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|decimal)(?: (?:zero|one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|decimal))*\\b')\n",
    "    return pattern.sub(replace_numbers, text)\n",
    "\n",
    "\n",
    "# 떨어져 있는 숫자 붙이기\n",
    "def attatch_numbers(text):\n",
    "    result = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', text)\n",
    "    return result\n",
    "\n",
    "def convert(text):\n",
    "    text = replace_thousands_and_hundreds(text)\n",
    "    text = replace_thousands(text)\n",
    "    text = replace_hundreds(text)\n",
    "    text = convert_big_numbers(text)\n",
    "    text = convert_words_to_numbers(text)\n",
    "    text = attatch_numbers(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mean_wer_whisper_number(df):\n",
    "    df['whisper_conv'] = df['whisper_text'].apply(lambda x: convert(x))\n",
    "    df['correct_conv'] = df['correct_text'].apply(lambda x: convert(x))\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_conv'], row['whisper_conv'])[4], axis=1)\n",
    "    return df['wer'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>whisper_text</th>\n",
       "      <th>correct_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atco2_test0.wav</td>\n",
       "      <td>oscar kilo foxtrot alfa oscar taxi to holding ...</td>\n",
       "      <td>oscar kilo foxtrot alfa oscar taxi to holding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atco2_test1.wav</td>\n",
       "      <td>ok call you soon four zero nine one resume to</td>\n",
       "      <td>ok quality 4091 ruzyne tower information lima ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atco2_test2.wav</td>\n",
       "      <td>car kilo echo lima alfa confirm proceeding to ...</td>\n",
       "      <td>oscar kilo echo lima alfa confirm proceeding t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atco2_test3.wav</td>\n",
       "      <td>saysay one delta zurich descend to flight leve...</td>\n",
       "      <td>csa 1 delta zulu descend flight level 100 no s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atco2_test4.wav</td>\n",
       "      <td>are you setting follow one hundred three three...</td>\n",
       "      <td>descending flight level 100 free speed csa 1 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>atco2_test866.wav</td>\n",
       "      <td>cindy tar air condor six forty two</td>\n",
       "      <td>sydney tower qantas 642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>atco2_test867.wav</td>\n",
       "      <td>cross six forty two is in attack good day</td>\n",
       "      <td>qantas 642 sydney tower good day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>atco2_test868.wav</td>\n",
       "      <td>jetset seven six one wind is coming romeo six ...</td>\n",
       "      <td>jetstar 761 wind is calm runway 16 right clear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>atco2_test869.wav</td>\n",
       "      <td>belair and one six right just seven six two off</td>\n",
       "      <td>cleared to land 16 right jetstar 761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>atco2_test870.wav</td>\n",
       "      <td>continue of course three four eleven and conti...</td>\n",
       "      <td>continue approach 3411 vacate via alfa 2 singa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>871 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file                                       whisper_text  \\\n",
       "0      atco2_test0.wav  oscar kilo foxtrot alfa oscar taxi to holding ...   \n",
       "1      atco2_test1.wav     ok call you soon four zero nine one resume to    \n",
       "2      atco2_test2.wav  car kilo echo lima alfa confirm proceeding to ...   \n",
       "3      atco2_test3.wav  saysay one delta zurich descend to flight leve...   \n",
       "4      atco2_test4.wav  are you setting follow one hundred three three...   \n",
       "..                 ...                                                ...   \n",
       "866  atco2_test866.wav                 cindy tar air condor six forty two   \n",
       "867  atco2_test867.wav          cross six forty two is in attack good day   \n",
       "868  atco2_test868.wav  jetset seven six one wind is coming romeo six ...   \n",
       "869  atco2_test869.wav    belair and one six right just seven six two off   \n",
       "870  atco2_test870.wav  continue of course three four eleven and conti...   \n",
       "\n",
       "                                          correct_text  \n",
       "0    oscar kilo foxtrot alfa oscar taxi to holding ...  \n",
       "1    ok quality 4091 ruzyne tower information lima ...  \n",
       "2    oscar kilo echo lima alfa confirm proceeding t...  \n",
       "3    csa 1 delta zulu descend flight level 100 no s...  \n",
       "4    descending flight level 100 free speed csa 1 d...  \n",
       "..                                                 ...  \n",
       "866                            sydney tower qantas 642  \n",
       "867                   qantas 642 sydney tower good day  \n",
       "868  jetstar 761 wind is calm runway 16 right clear...  \n",
       "869               cleared to land 16 right jetstar 761  \n",
       "870  continue approach 3411 vacate via alfa 2 singa...  \n",
       "\n",
       "[871 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_finetuned_mh_Tuned.csv', encoding='UTF-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64840090827054"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_wer_alphabet = get_mean_wer_whisper_number(df)\n",
    "mean_wer_alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923243086589043"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_test = get_mean_wer_whisper(df)\n",
    "wer_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have two apples and eighty one oranges. The price is one thousand two hundred dollars.\n",
      "                                        whisper_conv  \\\n",
      "0   Oskarkelo, focus throttle, false car, taxi do...   \n",
      "1  Ok, koli ty four thousand ninety one, rzhnět t...   \n",
      "2   Karkila EkoLema Alpha, conform procedím to ta...   \n",
      "3  CSAone Delta to Lodi, central at level one hun...   \n",
      "\n",
      "                                        correct_conv  \n",
      "0  Oscar kilo foxtrot alfa Oscar taxi to holding ...  \n",
      "1  ok quality four thousand ninety one ruzyne tow...  \n",
      "2  oscar kilo echo lima alfa confirm proceeding t...  \n",
      "3  csa one delta zulu descend flight level one hu...  \n"
     ]
    }
   ],
   "source": [
    "# 숫자 -> 알파벳\n",
    "import re\n",
    "\n",
    "# 숫자 단어와 실제 숫자의 매핑\n",
    "number_map = {\n",
    "    'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',\n",
    "    'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9',\n",
    "    'ten': '10', 'eleven': '11', 'twelve': '12', 'thirteen': '13', 'fourteen': '14',\n",
    "    'fifteen': '15', 'sixteen': '16', 'seventeen': '17', 'eighteen': '18', 'nineteen': '19',\n",
    "    'twenty': '20', 'thirty': '30', 'forty': '40', 'fifty': '50', 'sixty': '60',\n",
    "    'seventy': '70', 'eighty': '80', 'ninety': '90'\n",
    "}\n",
    "\n",
    "reverse_number_map = {v: k for k, v in number_map.items()}\n",
    "\n",
    "# 숫자를 단어로 변환하는 함수\n",
    "def convert_number_to_words(number):\n",
    "    if number == 0:\n",
    "        return 'zero'\n",
    "    if number < 20:\n",
    "        return reverse_number_map[str(number)]\n",
    "    elif number < 100:\n",
    "        tens, below_ten = divmod(number, 10)\n",
    "        return reverse_number_map[str(tens * 10)] + (' ' + reverse_number_map[str(below_ten)] if below_ten else '')\n",
    "    elif number < 1000:\n",
    "        hundreds, below_hundred = divmod(number, 100)\n",
    "        return reverse_number_map[str(hundreds)] + ' hundred' + (' ' + convert_number_to_words(below_hundred) if below_hundred else '')\n",
    "    else:\n",
    "        thousands, below_thousand = divmod(number, 1000)\n",
    "        return convert_number_to_words(thousands) + ' thousand' + (' ' + convert_number_to_words(below_thousand) if below_thousand else '')\n",
    "\n",
    "# 텍스트에서 숫자를 단어로 변환하는 함수\n",
    "def convert_numbers_to_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # 숫자를 찾는 정규식 패턴\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    return pattern.sub(lambda x: convert_number_to_words(int(x.group())), text)\n",
    "\n",
    "# 테스트\n",
    "text = \"I have 2 apples and 81 oranges. The price is 1200 dollars.\"\n",
    "converted_text = convert_numbers_to_words(text)\n",
    "print(converted_text)  # 결과: I have two apples and eighty one oranges. The price is one thousand two hundred dollars.\n",
    "\n",
    "# 데이터프레임에서 함수 적용\n",
    "import pandas as pd\n",
    "\n",
    "# 예시 데이터프레임\n",
    "data = {\n",
    "    \"file\": [\"atco2_test0.wav\", \"atco2_test1.wav\", \"atco2_test2.wav\", \"atco2_test3.wav\"],\n",
    "    \"whisper_text\": [\n",
    "        \"Oskarkelo, focus throttle, false car, taxi do...\",\n",
    "        \"Ok, koli ty 4091, rzhnět tower informatíčná, ...\",\n",
    "        \"Karkila EkoLema Alpha, conform procedím to ta...\",\n",
    "        \"CSA1 Delta to Lodi, central at level 108, no ...\"\n",
    "    ],\n",
    "    \"correct_text\": [\n",
    "        \"Oscar kilo foxtrot alfa Oscar taxi to holding ...\",\n",
    "        \"ok quality 4091 ruzyne tower information lima ...\",\n",
    "        \"oscar kilo echo lima alfa confirm proceeding t...\",\n",
    "        \"csa 1 delta zulu descend flight level 100 no s...\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 데이터프레임의 각 행에 함수 적용\n",
    "df['whisper_conv'] = df['whisper_text'].apply(lambda x: convert_numbers_to_words(x))\n",
    "df['correct_conv'] = df['correct_text'].apply(lambda x: convert_numbers_to_words(x))\n",
    "\n",
    "print(df[['whisper_conv', 'correct_conv']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_wer_whisper_alphabet(df):\n",
    "    df['whisper_conv'] = df['whisper_text'].apply(lambda x: convert_numbers_to_words(x))\n",
    "    df['correct_conv'] = df['correct_text'].apply(lambda x: convert_numbers_to_words(x))\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_conv'], row['whisper_conv'])[4], axis=1)\n",
    "    return df['wer'].mean()\n",
    "\n",
    "\n",
    "def get_mean_wer_llama_alphabet(df):\n",
    "    df['whisper_conv'] = df['llm_text'].apply(lambda x: convert_numbers_to_words(x))\n",
    "    df['correct_conv'] = df['correct_text'].apply(lambda x: convert_numbers_to_words(x))\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_conv'], row['whisper_conv'])[4], axis=1)\n",
    "    return df['wer'].mean()\n",
    "\n",
    "\n",
    "def get_mean_wer_llama_ft_alphabet(df):\n",
    "    df['whisper_conv'] = df['llm_output_text'].apply(lambda x: convert_numbers_to_words(x))\n",
    "    df['correct_conv'] = df['correct_text'].apply(lambda x: convert_numbers_to_words(x))\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_conv'], row['whisper_conv'])[4], axis=1)\n",
    "    return df['wer'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9026089834468001"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_small.csv', encoding='UTF-8')\n",
    "alphabet_mean_wer_1 = get_mean_wer_whisper_alphabet(df)\n",
    "alphabet_mean_wer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9191547865206413"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_finetuned.csv', encoding='UTF-8')\n",
    "alphabet_mean_wer_2 = get_mean_wer_whisper_alphabet(df)\n",
    "alphabet_mean_wer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9437961681222905"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_small_and_llama2_original.csv', encoding='UTF-8')\n",
    "alphabet_mean_wer_3 = get_mean_wer_llama_alphabet(df)\n",
    "alphabet_mean_wer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8311526276159446"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_finetuned_and_llama2_original.csv', encoding='UTF-8')\n",
    "alphabet_mean_wer_4 = get_mean_wer_llama_alphabet(df)\n",
    "alphabet_mean_wer_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8550298274371527"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Whisper에 llama2 finetuned 붙여서 ATCO2 WER 뽑기_결과.csv', encoding='UTF-8')\n",
    "alphabet_mean_wer_5 = get_mean_wer_llama_ft_alphabet(df)\n",
    "alphabet_mean_wer_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7574159781717675"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Whisper 파인튜닝한 모델에 llama2 finetuned 붙여서 ATCO2 WER 뽑기_결과.csv', encoding='UTF-8')\n",
    "alphabet_mean_wer_6 = get_mean_wer_llama_ft_alphabet(df)\n",
    "alphabet_mean_wer_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "위스퍼 기본모델              :  1.0405270031874403\n",
      "위스퍼 기본모델              :  0.9026089834468001\n",
      "위스퍼 파인튜닝              :  1.0495432499523087\n",
      "위스퍼 파인튜닝              :  0.9191547865206413\n",
      "위스퍼 기본모델 + 라마 기본모델 :  1.068548207134803\n",
      "위스퍼 기본모델 + 라마 기본모델 :  0.9437961681222905\n",
      "위스퍼 파인튜닝 + 라마 기본모델 :  0.9536716822147444\n",
      "위스퍼 파인튜닝 + 라마 기본모델 :  0.8311526276159446\n",
      "위스퍼 기본모델 + 라마 파인튜닝 :  0.8557662425136696\n",
      "위스퍼 기본모델 + 라마 파인튜닝 :  0.8550298274371527\n",
      "위스퍼 기본모델 + 라마 파인튜닝 :  0.7405766128636935\n",
      "위스퍼 기본모델 + 라마 파인튜닝 :  0.7574159781717675\n"
     ]
    }
   ],
   "source": [
    "print(\"위스퍼 기본모델              : \", mean_wer_1)\n",
    "print(\"위스퍼 기본모델              : \", alphabet_mean_wer_1)\n",
    "print(\"위스퍼 파인튜닝              : \", mean_wer_2)\n",
    "print(\"위스퍼 파인튜닝              : \", alphabet_mean_wer_2)\n",
    "print(\"위스퍼 기본모델 + 라마 기본모델 : \", mean_wer_3)\n",
    "print(\"위스퍼 기본모델 + 라마 기본모델 : \", alphabet_mean_wer_3)\n",
    "print(\"위스퍼 파인튜닝 + 라마 기본모델 : \", mean_wer_4)\n",
    "print(\"위스퍼 파인튜닝 + 라마 기본모델 : \", alphabet_mean_wer_4)\n",
    "print(\"위스퍼 기본모델 + 라마 파인튜닝 : \", mean_wer_5)\n",
    "print(\"위스퍼 기본모델 + 라마 파인튜닝 : \", alphabet_mean_wer_5)\n",
    "print(\"위스퍼 기본모델 + 라마 파인튜닝 : \", mean_wer_6)\n",
    "print(\"위스퍼 기본모델 + 라마 파인튜닝 : \", alphabet_mean_wer_6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
