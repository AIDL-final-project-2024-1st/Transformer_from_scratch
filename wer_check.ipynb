{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WER / CER 계산 코드 (구현)\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "# locale.getpreferredencoding()\n",
    "# !pip install Levenshtein\n",
    "import Levenshtein as Lev\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_wer(ref, hyp ,debug=False):\n",
    "        # Handle NaN values by converting them to empty strings\n",
    "    if pd.isna(ref):\n",
    "        ref = \"\"\n",
    "    if pd.isna(hyp):\n",
    "        hyp = \"\"\n",
    "    r = ref.split()\n",
    "    h = hyp.split()\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    # backtrace will hold the operations we've done.\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "\n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "\n",
    "    DEL_PENALTY=1 # Tact\n",
    "    INS_PENALTY=1 # Tact\n",
    "    SUB_PENALTY=1 # Tact\n",
    "    # First column represents the case where we achieve zero\n",
    "    # hypothesis words by deleting all reference words.\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "\n",
    "    # First row represents the case where we achieve the hypothesis\n",
    "    # by inserting all hypothesis words into a zero-length reference.\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "\n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "\n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        print(\"OP\\tREF\\tHYP\")\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    if debug:\n",
    "        lines = reversed(lines)\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "        print(\"Ncor \" + str(numCor))\n",
    "        print(\"Nsub \" + str(numSub))\n",
    "        print(\"Ndel \" + str(numDel))\n",
    "        print(\"Nins \" + str(numIns))\n",
    "    return numCor, numSub, numDel, numIns, (numSub + numDel + numIns) / (float) (len(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mean_wer_whisper(df):\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_text'], row['whisper_text'])[4], axis=1)\n",
    "    return df['wer'].mean()\n",
    "\n",
    "def get_mean_wer_llama(df):\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_text'], row['llm_text'])[4], axis=1)\n",
    "    return df['wer'].mean()\n",
    "\n",
    "def get_mean_wer_llama_ft(df):\n",
    "    df['wer'] = df.apply(lambda row: calculate_wer(row['correct_text'], row['llm_output_text'])[4], axis=1)\n",
    "    return df['wer'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0405270031874403"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('atco2_test_dictation_by_whisper_small.csv', encoding='UTF-8')\n",
    "mean_wer_1 = get_mean_wer_whisper(df)\n",
    "mean_wer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0495432499523087"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_finetuned.csv', encoding='UTF-8')\n",
    "mean_wer_2 = get_mean_wer_whisper(df)\n",
    "mean_wer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.068548207134803"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_small_and_llama2_original.csv', encoding='UTF-8')\n",
    "mean_wer_3 = get_mean_wer_llama(df)\n",
    "mean_wer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9536716822147444"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('atco2_test_dictation_by_whisper_finetuned_and_llama2_original.csv', encoding='UTF-8')\n",
    "mean_wer_4 = get_mean_wer_llama(df)\n",
    "mean_wer_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8557662425136696"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Whisper에 llama2 finetuned 붙여서 ATCO2 WER 뽑기_결과.csv', encoding='UTF-8')\n",
    "mean_wer_5 = get_mean_wer_llama_ft(df)\n",
    "mean_wer_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7405766128636935"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Whisper 파인튜닝한 모델에 llama2 finetuned 붙여서 ATCO2 WER 뽑기_결과.csv', encoding='UTF-8')\n",
    "mean_wer_6 = get_mean_wer_llama_ft(df)\n",
    "mean_wer_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "위스퍼 기본모델              :  1.0405270031874403\n",
      "위스퍼 파인튜닝              :  1.0495432499523087\n",
      "위스퍼 기본모델 + 라마 기본모델 :  1.068548207134803\n",
      "위스퍼 파인튜닝 + 라마 기본모델 :  0.9536716822147444\n",
      "위스퍼 기본모델 + 라마 파인튜닝 :  0.8557662425136696\n",
      "위스퍼 기본모델 + 라마 파인튜닝 :  0.7405766128636935\n"
     ]
    }
   ],
   "source": [
    "print(\"위스퍼 기본모델              : \", mean_wer_1)\n",
    "print(\"위스퍼 파인튜닝              : \", mean_wer_2)\n",
    "print(\"위스퍼 기본모델 + 라마 기본모델 : \", mean_wer_3)\n",
    "print(\"위스퍼 파인튜닝 + 라마 기본모델 : \", mean_wer_4)\n",
    "print(\"위스퍼 기본모델 + 라마 파인튜닝 : \", mean_wer_5)\n",
    "print(\"위스퍼 기본모델 + 라마 파인튜닝 : \", mean_wer_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
